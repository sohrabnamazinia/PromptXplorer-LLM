Loading CSV...
Loaded 1000 rows.
Tokenizing and cleaning prompts...
Tokenized and cleaned 1000 prompts.
Creating dictionary and corpus...
Dictionary size: 1506 unique tokens.
Training LDA model...
Saving model and dictionary...

Discovered Topics:
Topic 0: 0.036*"portrait" + 0.019*"character" + 0.018*"closeup" + 0.018*"painted" + 0.013*"man" + 0.012*"design" + 0.012*"cute" + 0.011*"hyperrealistic" + 0.011*"environment" + 0.011*"scenic"
Topic 1: 0.043*"beautiful" + 0.038*"architecture" + 0.033*"building" + 0.021*"industrial" + 0.021*"detailed" + 0.020*"urbex" + 0.019*"nature" + 0.019*"unfinished" + 0.014*"city" + 0.014*"abandoned"

Saving topics to 'lda_topics.txt'...
Done.
