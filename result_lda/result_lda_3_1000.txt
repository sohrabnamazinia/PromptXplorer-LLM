Loading CSV...
Loaded 1000 rows.
Tokenizing and cleaning prompts...
Tokenized and cleaned 1000 prompts.
Creating dictionary and corpus...
Dictionary size: 1506 unique tokens.
Training LDA model...
Saving model and dictionary...

Discovered Topics:
Topic 0: 0.044*"portrait" + 0.032*"closeup" + 0.031*"painted" + 0.021*"cute" + 0.017*"tiny" + 0.017*"chinese" + 0.016*"mascot" + 0.016*"spring" + 0.016*"oriental" + 0.016*"tale"
Topic 1: 0.043*"architecture" + 0.038*"building" + 0.037*"beautiful" + 0.024*"industrial" + 0.023*"urbex" + 0.022*"nature" + 0.022*"unfinished" + 0.020*"detailed" + 0.016*"abandoned" + 0.015*"city"
Topic 2: 0.033*"character" + 0.023*"portrait" + 0.021*"highly" + 0.019*"hyperrealistic" + 0.019*"scenic" + 0.019*"environment" + 0.018*"philippine" + 0.018*"detailed" + 0.014*"white" + 0.013*"red"

Saving topics to 'lda_topics.txt'...
Done.
